{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b16be798",
   "metadata": {},
   "source": [
    "This file will create a speech recognition, too which someone can talk into their microphone, and the speech will be transcripted into text. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc876b5f",
   "metadata": {},
   "source": [
    "Need to perform 2 tasks at the same time; one too continiously record the microphone, and the other too transcribe word too text. Way we do this is through threads (functions which run in the background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b13ec39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbdf634b1414a1cb6ec103bceb9173b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Record', icon='microphone', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63553d569e1b432ebbc28f9d1825f991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Stop', icon='stop', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349e117e28f14896bb2a8fa6862622f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "messages = Queue()\n",
    "recordings = Queue()\n",
    "\n",
    "#Setting up widget for recording \n",
    "record_button = widgets.Button(\n",
    "    description = 'Record',\n",
    "    disabled = False,\n",
    "    button_style = 'success',\n",
    "    icon = 'microphone'\n",
    ")\n",
    "\n",
    "#Setting up widget for stopping the recording \n",
    "stop_button = widgets.Button(\n",
    "    description = 'Stop',\n",
    "    disabled = False,\n",
    "    button_style = 'warning',\n",
    "    icon = 'stop'\n",
    ")\n",
    "\n",
    "#Widget too show transcript as it's generated\n",
    "output = widgets.Output()\n",
    "\n",
    "#Function for when we start recording\n",
    "def start_recording(data):\n",
    "    messages.put(True)\n",
    "    \n",
    "    with output:\n",
    "        display('Starting...')\n",
    "        record = Thread(target = record_microphone)\n",
    "        record.start()\n",
    "        \n",
    "        transcribe = Thread(target = speech_recognition, args = (output,))\n",
    "        transcribe.start()\n",
    "\n",
    "#Function for when we stop recording\n",
    "def stop_recording(data):\n",
    "    with output:\n",
    "        messages.get()\n",
    "        display('Stopped.')\n",
    "\n",
    "\n",
    "#Linking widgets too functions above\n",
    "record_button.on_click(start_recording)\n",
    "stop_button.on_click(stop_recording)\n",
    "\n",
    "display(record_button, stop_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f8d8bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 0, 'structVersion': 2, 'name': 'BlackHole 2ch', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.0014512471655328798, 'defaultHighInputLatency': 0.1, 'defaultHighOutputLatency': 0.011609977324263039, 'defaultSampleRate': 44100.0}\n",
      "{'index': 1, 'structVersion': 2, 'name': 'MacBook Pro Microphone', 'hostApi': 0, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.03414965986394558, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.05591836734693877, 'defaultHighOutputLatency': 0.1, 'defaultSampleRate': 44100.0}\n",
      "{'index': 2, 'structVersion': 2, 'name': 'MacBook Pro Speakers', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.009229024943310658, 'defaultHighInputLatency': 0.1, 'defaultHighOutputLatency': 0.019387755102040816, 'defaultSampleRate': 44100.0}\n",
      "{'index': 3, 'structVersion': 2, 'name': 'Microsoft Teams Audio', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.0013333333333333333, 'defaultHighInputLatency': 0.1, 'defaultHighOutputLatency': 0.010666666666666666, 'defaultSampleRate': 48000.0}\n",
      "{'index': 4, 'structVersion': 2, 'name': 'Screen Record Input', 'hostApi': 0, 'maxInputChannels': 3, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.002925170068027211, 'defaultHighInputLatency': 0.1, 'defaultHighOutputLatency': 0.013083900226757369, 'defaultSampleRate': 44100.0}\n",
      "{'index': 5, 'structVersion': 2, 'name': 'Screen Record Output', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.005396825396825397, 'defaultHighInputLatency': 0.1, 'defaultHighOutputLatency': 0.015555555555555555, 'defaultSampleRate': 44100.0}\n"
     ]
    }
   ],
   "source": [
    "#Need to figure out which of our sound devices we woud like too use\n",
    "import pyaudio\n",
    "\n",
    "#Initalize pyaudio connection too system audio devices\n",
    "p = pyaudio.PyAudio()\n",
    "#Loop through too print and see all of our audio devices\n",
    "for i in range(p.get_device_count()):\n",
    "    print(p.get_device_info_by_index(i))\n",
    "    \n",
    "p.terminate() #Terminate pyaudio connection to audio devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebde0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants too define how our audio will be recorded\n",
    "CHANNELS = 1\n",
    "FRAME_RATE = 16000 #How high quality recording is\n",
    "RECORD_SECONDS = 5 #How many seconds we want too record audio for before transcription\n",
    "AUDIO_FORMAT = pyaudio.paInt16\n",
    "SAMPLE_SIZE = 2\n",
    "\n",
    "def record_microphone(chunk = 1024): #chunk defines how often we read from microphone\n",
    "    p = pyaudio.PyAudio()\n",
    "    \n",
    "    #Going too connect too our microphone and record\n",
    "    stream = p.open(format = AUDIO_FORMAT,\n",
    "                    channels = CHANNELS,\n",
    "                    rate = FRAME_RATE,\n",
    "                    input = True,\n",
    "                    input_device_index = 1,\n",
    "                    frames_per_buffer = chunk)\n",
    "    \n",
    "    frames = [] #Store all of our audio\n",
    "    \n",
    "    while not messages.empty():\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "        \n",
    "        #Setting up so every given seconds will send our audio data too transcription, then start new collection of audio\n",
    "        if len(frames) >= (FRAME_RATE * RECORD_SECONDS) / chunk:\n",
    "            recordings.put(frames.copy())\n",
    "            frames = [] #Need to empty frames once for next chunk of audio data coming in\n",
    "    \n",
    "    #Need too stop and close connection once we're done recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06879b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /Users/brandonamarasingam/.cache/vosk/vosk-model-small-en-us-0.15/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from /Users/brandonamarasingam/.cache/vosk/vosk-model-small-en-us-0.15/graph/HCLr.fst /Users/brandonamarasingam/.cache/vosk/vosk-model-small-en-us-0.15/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo /Users/brandonamarasingam/.cache/vosk/vosk-model-small-en-us-0.15/graph/phones/word_boundary.int\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe following lines are in relation too including punctuation within our transcription. Due too storage issues,\\nI will comment this part out for now, but what the following lines of code will allow for punctuations and capitilization\\ntoo be included within the transcription. \\nhttps://github.com/benob/recasepunc\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "#Various models too use, will use the smallest sized one\n",
    "#https://alphacephei.com/vosk/models\n",
    "model = Model(model_name = \"vosk-model-small-en-us-0.15\")\n",
    "\n",
    "#Create recognizer which will use model for speech recognition\n",
    "rec = KaldiRecognizer(model, FRAME_RATE)\n",
    "rec.SetWords(True) #Will give us confidence level for words\n",
    "\n",
    "#Function too take in output widget too display transcription live\n",
    "def speech_recognition(output):\n",
    "    while not messages.empty(): #Making sure we haven't clicked stop recording\n",
    "        frames = recordings.get() #Pulling data out of queue \n",
    "        rec.AcceptWaveform(b''.join(frames)) #Joining all chunks of our frames into one \n",
    "        result = rec.Result()\n",
    "        text = json.loads(result)['text']\n",
    "        output.append_stdout(text) #Delete this line if using lines of code commented out below\n",
    "        \n",
    "'''\n",
    "The following lines are in relation too including punctuation within our transcription. Due too storage issues,\n",
    "I will comment this part out for now, but what the following lines of code will allow for punctuations and capitilization\n",
    "too be included within the transcription. \n",
    "https://github.com/benob/recasepunc\n",
    "'''\n",
    "        #cased = subproces.check_output('python recasepunc/recasepunc.py predict recasepunc/checkpoint', shell = True, text = True, input = text)\n",
    "        #output.append_stdout(cased) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
